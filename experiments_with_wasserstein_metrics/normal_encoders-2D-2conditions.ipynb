{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "normal_encoders-2D-2conditions.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JdZHb5gKCi2",
        "outputId": "994ba6ec-fe43-4f55-b8fb-d450228af88c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install memory_profiler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp36-none-any.whl size=30181 sha256=03be3cc83f6371637556d4606d22e1de7fc070c28cf806f7980a4a97b97554f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6mMNI3AKCi5"
      },
      "source": [
        "%load_ext memory_profiler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7pvwIrDKCi6"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.stats import wasserstein_distance\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd.variable import Variable\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNNh10tVKCi6"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
        "# device = torch.device('cpu')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t23HwfXEKCi6"
      },
      "source": [
        "np.random.seed(6345)\n",
        "torch.manual_seed(6345)\n",
        "set_dist = []\n",
        "\n",
        "\n",
        "for i in range(50): \n",
        "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "    x = m.sample([250])\n",
        "    set_dist.append(x) \n",
        "    \n",
        "for i in range(50): \n",
        "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0.0, 1.0]), torch.tensor([[1,.5],[.5,1]]))\n",
        "    x = m.sample([250])\n",
        "    set_dist.append(x) \n",
        "    \n",
        "for i in range(50): \n",
        "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.ones(2), covariance_matrix=torch.tensor([[.7,.1],[.1,1]]))\n",
        "    x = m.sample([250])\n",
        "    set_dist.append(x) \n",
        "    \n",
        "for i in range(50): \n",
        "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([1.0, 0.0]), torch.tensor([[.2, -.1], [-.1, 1]]))\n",
        "    x = m.sample([250])\n",
        "    set_dist.append(x) \n",
        "    \n",
        "for i in range(50): \n",
        "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([.5, .5]), torch.tensor([[.8,.4],[.4,1]]))\n",
        "    x = m.sample([250])\n",
        "    set_dist.append(x) \n",
        "    \n",
        "for i in range(50): \n",
        "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([-.25, -.5]), torch.eye(2)*.5)\n",
        "    x = m.sample([250])\n",
        "    set_dist.append(x) \n",
        "    \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpAaXpgKKCi6"
      },
      "source": [
        "set_dist = torch.stack(set_dist)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLR6_OIJKCi6",
        "outputId": "3091fbbf-94ee-464b-cbdb-11b00016ea80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_dist.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([300, 250, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MlVIR4bKCi7"
      },
      "source": [
        "class Set2Set(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, act_fn=nn.Tanh, num_layers=1):\n",
        "        '''\n",
        "        Args:\n",
        "            input_dim: input dim of Set2Set. \n",
        "            hidden_dim: the dim of set representation, which is also the INPUT dimension of \n",
        "                the LSTM in Set2Set. \n",
        "                This is a concatenation of weighted sum of embedding (dim input_dim), and the LSTM\n",
        "                hidden/output (dim: self.lstm_output_dim).\n",
        "        '''\n",
        "        super(Set2Set, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        if hidden_dim <= input_dim:\n",
        "            print('ERROR: Set2Set output_dim should be larger than input_dim')\n",
        "        # the hidden is a concatenation of weighted sum of embedding and LSTM output\n",
        "        self.lstm_output_dim = hidden_dim - input_dim\n",
        "        self.lstm = nn.LSTM(hidden_dim, input_dim, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # convert back to dim of input_dim\n",
        "       # self.pred = nn.Linear(hidden_dim, input_dim)\n",
        "        self.pred = nn.Linear(hidden_dim,4)\n",
        "        self.act = act_fn()\n",
        "\n",
        "    def forward(self, embedding):\n",
        "        '''\n",
        "        Args:\n",
        "            embedding: [batch_size x n x d] embedding matrix\n",
        "        Returns:\n",
        "            aggregated: [batch_size x d] vector representation of all embeddings\n",
        "        '''\n",
        "        batch_size = embedding.size()[0]\n",
        "        n = embedding.size()[1]\n",
        "\n",
        "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
        "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
        "\n",
        "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
        "        for i in range(n):\n",
        "            # q: batch_size x 1 x input_dim\n",
        "            q, hidden = self.lstm(q_star, hidden)\n",
        "            # e: batch_size x n x 1\n",
        "            e = embedding @ torch.transpose(q, 1, 2)\n",
        "            a = nn.Softmax(dim=1)(e)\n",
        "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
        "            q_star = torch.cat((q, r), dim=2)\n",
        "        q_star = torch.squeeze(q_star, dim=1)\n",
        "        out = self.act(self.pred(q_star))\n",
        "\n",
        "        return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5GqUmExKCi7"
      },
      "source": [
        "class DeepSet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, set_features):\n",
        "        super(DeepSet, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = set_features\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(in_features, 50),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(50, 100),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(100, set_features)\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(set_features, 30),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(30, 30),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(30, 10),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(10, 2),\n",
        "        )\n",
        "        \n",
        "        \n",
        "    def forward(self, input):\n",
        "        x = input\n",
        "        x = self.feature_extractor(x)\n",
        "        x = x.sum(dim=1)\n",
        "        x = self.regressor(x)\n",
        "        return x\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLQhlr1QKCi7"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\" Set Encoder \n",
        "    \"\"\"\n",
        "    def __init__(self, dim_Q, dim_K, dim_V, d_model, num_heads, ln=False, skip=True):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dim_V = dim_V\n",
        "        self.num_heads = num_heads\n",
        "        self.skip = skip\n",
        "       # self.s_max = s_max\n",
        "        #Maximum set size\n",
        "        self.d_model = d_model\n",
        "        self.fc_q = nn.Linear(dim_Q, d_model)\n",
        "        self.fc_k = nn.Linear(dim_K, d_model)\n",
        "        self.fc_v = nn.Linear(dim_K, d_model)\n",
        "        if ln:\n",
        "            self.ln0 = nn.LayerNorm(d_model)\n",
        "            self.ln1 = nn.LayerNorm(d_model)\n",
        "        #This is the classic pointwise feedforward in \"Attention is All you need\"\n",
        "        self.ff = nn.Sequential(\n",
        "        nn.Linear(d_model, 4 * d_model),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * d_model, d_model))\n",
        "        # I have experimented with just a smaller version of this \n",
        "       # self.fc_o = nn.Linear(d_model,d_model)\n",
        "        \n",
        "     #   self.fc_rep = nn.Linear(s_max, 1)\n",
        "#number of heads must divide output size = d_model\n",
        "        \n",
        "\n",
        "    def forward(self, Q, K):\n",
        "        Q = self.fc_q(Q)\n",
        "      \n",
        "        K, V = self.fc_k(K), self.fc_v(K)\n",
        "\n",
        "        dim_split = self.d_model // self.num_heads\n",
        "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
        "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
        "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
        "  \n",
        "\n",
        "        A = torch.softmax(Q_.bmm(K_.transpose(-2,-1))/math.sqrt(self.d_model), dim=-1)\n",
        "        A_1 = A.bmm(V_)\n",
        "        \n",
        " \n",
        "        O = torch.cat((A_1).split(Q.size(0), 0), 2)\n",
        "       \n",
        "        O = torch.cat((Q_ + A_1).split(Q.size(0), 0), 2) if getattr(self, 'skip', True) else \\\n",
        "             torch.cat((A_1).split(Q.size(0), 0), 2)\n",
        "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
        "       # O = O + F.relu(self.fc_o(O)) if getattr(self, 'skip', None) is None else F.relu(self.fc_o(O))\n",
        "        # For the classic transformers paper it is \n",
        "        O = O + self.ff(O)\n",
        "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
        "        O = torch.mean(O,dim=1)\n",
        "#         O = pad_sequence(O, batch_first=True, padding_value=0)\n",
        "#         O = O.transpose(-2,-1)\n",
        "#         O = F.pad(O, (0, self.s_max- O.shape[-1]), 'constant', 0)\n",
        "      #  O = self.fc_rep(O)\n",
        "       # O = self.fc_rep(O.transpose(-2,-1))\n",
        "      #  O = O.squeeze()\n",
        "\n",
        "        return O"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "534rAW4YKCi7"
      },
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, dim_in=18, dim_out=8, num_heads=2, ln=True, skip=True):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.Encoder = Encoder(dim_in, dim_in, dim_in, dim_out, num_heads, ln=ln, skip=skip)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.Encoder(X, X)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9pj8l9vKCi7"
      },
      "source": [
        "eps = 1e-15\n",
        "\"\"\"Approximating KL divergences between two probability densities using samples. \n",
        "    It is buggy. Use at your own peril\n",
        "\"\"\"\n",
        "\n",
        "def knn_distance(point, sample, k):\n",
        "    \"\"\" Euclidean distance from `point` to it's `k`-Nearest\n",
        "    Neighbour in `sample` \"\"\"\n",
        "    norms = np.linalg.norm(sample-point, axis=1)\n",
        "    return np.sort(norms)[k]\n",
        "\n",
        "\n",
        "def verify_sample_shapes(s1, s2, k):\n",
        "    # Expects [N, D]\n",
        "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
        "    # Check dimensionality of sample is identical\n",
        "    assert(s1.shape[1] == s2.shape[1])\n",
        "\n",
        "\n",
        "def naive_estimator(s1, s2, k=1):\n",
        "    \"\"\" KL-Divergence estimator using brute-force (numpy) k-NN\n",
        "        s1: (N_1,D) Sample drawn from distribution P\n",
        "        s2: (N_2,D) Sample drawn from distribution Q\n",
        "        k: Number of neighbours considered (default 1)\n",
        "        return: estimated D(P|Q)\n",
        "    \"\"\"\n",
        "    verify_sample_shapes(s1, s2, k)\n",
        "\n",
        "    n, m = len(s1), len(s2)\n",
        "    D = np.log(m / (n - 1))\n",
        "    d = float(s1.shape[1])\n",
        "\n",
        "    for p1 in s1:\n",
        "        nu = knn_distance(p1, s2, k-1)  # -1 because 'p1' is not in 's2'\n",
        "        rho = knn_distance(p1, s1, k)\n",
        "        D += (d/n)*np.log((nu/rho)+eps)\n",
        "    return D\n",
        "\n",
        "\n",
        "def scipy_estimator(s1, s2, k=1):\n",
        "    \"\"\" KL-Divergence estimator using scipy's KDTree\n",
        "        s1: (N_1,D) Sample drawn from distribution P\n",
        "        s2: (N_2,D) Sample drawn from distribution Q\n",
        "        k: Number of neighbours considered (default 1)\n",
        "        return: estimated D(P|Q)\n",
        "    \"\"\"\n",
        "    verify_sample_shapes(s1, s2, k)\n",
        "\n",
        "    n, m = len(s1), len(s2)\n",
        "    d = float(s1.shape[1])\n",
        "    D = np.log(m / (n - 1))\n",
        "\n",
        "    nu_d,  nu_i   = KDTree(s2).query(s1, k)\n",
        "    rho_d, rhio_i = KDTree(s1).query(s1, k+1)\n",
        "\n",
        "    # KTree.query returns different shape in k==1 vs k > 1\n",
        "    if k > 1:\n",
        "        D += (d/n)*np.sum(np.log(nu_d[::, -1]/rho_d[::, -1]))\n",
        "    else:\n",
        "        D += (d/n)*np.sum(np.log(nu_d/rho_d[::, -1]))\n",
        "\n",
        "    return D\n",
        "\n",
        "\n",
        "def skl_estimator(s1, s2, k=1):\n",
        "    \"\"\" KL-Divergence estimator using scikit-learn's NearestNeighbours\n",
        "        s1: (N_1,D) Sample drawn from distribution P\n",
        "        s2: (N_2,D) Sample drawn from distribution Q\n",
        "        k: Number of neighbours considered (default 1)\n",
        "        return: estimated D(P|Q)\n",
        "    \"\"\"\n",
        "    verify_sample_shapes(s1, s2, k)\n",
        "\n",
        "    n, m = len(s1), len(s2)\n",
        "    d = float(s1.shape[1])\n",
        "    D = np.log(m / (n - 1))\n",
        "\n",
        "    s1_neighbourhood = NearestNeighbors(k+1, 10).fit(s1)\n",
        "    s2_neighbourhood = NearestNeighbors(k, 10).fit(s2)\n",
        "\n",
        "    for p1 in s1:\n",
        "        s1_distances, indices = s1_neighbourhood.kneighbors([p1], k+1)\n",
        "        s2_distances, indices = s2_neighbourhood.kneighbors([p1], k)\n",
        "        rho = s1_distances[0][-1]\n",
        "        nu = s2_distances[0][-1]\n",
        "        D += (d/n)*np.log(nu/rho)\n",
        "    return D\n",
        "\n",
        "def calculate_loss(batch, n_data, a, y, y_a, y_translate):\n",
        "  loss = [0,0,0]\n",
        "  y_norm = torch.pdist(y)\n",
        "  n_data_pairwise_1 = []\n",
        "  n_data_pairwise_2 = []\n",
        "  for i in range(len(batch)):\n",
        "      for j in range(i+1,len(batch)):\n",
        "        n_data_pairwise_1.append(n_data[i])\n",
        "        n_data_pairwise_2.append(n_data[j])\n",
        "  n_data_pairwise_1 = torch.stack(n_data_pairwise_1)\n",
        "  n_data_pairwise_2 = torch.stack(n_data_pairwise_2)\n",
        "  w_norm = sinkhorn(n_data_pairwise_2, n_data_pairwise_1)\n",
        "  y_a_norm = torch.pdist(y_a)\n",
        "  y_translate_norm = torch.pdist(y_translate)\n",
        "  loss[0] = (y_norm - w_norm).abs().sum()\n",
        "  loss[1] = ((y_a_norm - a * y_norm) ** 2).sum()\n",
        "  loss[2] = ((y_translate_norm - y_norm) ** 2).sum()\n",
        "  loss = sum(loss)\n",
        "  return loss\n",
        "\n",
        "# List of all estimators\n",
        "Estimators = [naive_estimator, scipy_estimator, skl_estimator]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w_SJQjrKCi8"
      },
      "source": [
        "class SinkhornDistance(nn.Module):\n",
        "    r\"\"\"\n",
        "    Given two empirical measures each with :math:`P_1` locations\n",
        "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
        "    outputs an approximation of the regularized OT cost for point clouds.\n",
        "    Args:\n",
        "        eps (float): regularization coefficient\n",
        "        max_iter (int): maximum number of Sinkhorn iterations\n",
        "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
        "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
        "            'mean': the sum of the output will be divided by the number of\n",
        "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
        "    Shape:\n",
        "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
        "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
        "    \"\"\"\n",
        "    def __init__(self, eps, max_iter, reduction='none'):\n",
        "        super(SinkhornDistance, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.max_iter = max_iter\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # The Sinkhorn algorithm takes as input three variables :\n",
        "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
        "        x_points = x.shape[-2]\n",
        "        y_points = y.shape[-2]\n",
        "        if x.dim() == 2:\n",
        "            batch_size = 1\n",
        "        else:\n",
        "            batch_size = x.shape[0]\n",
        "\n",
        "        # both marginals are fixed with equal weights\n",
        "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
        "                         requires_grad=False).fill_(1.0 / x_points).to(device).squeeze()\n",
        "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
        "                         requires_grad=False).fill_(1.0 / y_points).to(device).squeeze()\n",
        "\n",
        "        u = torch.zeros_like(mu).to(device)\n",
        "        v = torch.zeros_like(nu).to(device)\n",
        "        # To check if algorithm terminates because of threshold\n",
        "        # or max iterations reached\n",
        "        actual_nits = 0\n",
        "        # Stopping criterion\n",
        "        thresh = 1e-1\n",
        "\n",
        "        # Sinkhorn iterations\n",
        "        for i in range(self.max_iter):\n",
        "            u1 = u  # useful to check the update\n",
        "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
        "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
        "            err = (u - u1).abs().sum(-1).mean()\n",
        "\n",
        "            actual_nits += 1\n",
        "            if err.item() < thresh:\n",
        "                break\n",
        "\n",
        "        U, V = u, v\n",
        "        # Transport plan pi = diag(a)*K*diag(b)\n",
        "        pi = torch.exp(self.M(C, U, V))\n",
        "        # Sinkhorn distance\n",
        "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            cost = cost.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            cost = cost.sum()\n",
        "\n",
        "      #  return cost, pi, C\n",
        "        return cost\n",
        "\n",
        "    def M(self, C, u, v):\n",
        "        \"Modified cost for logarithmic updates\"\n",
        "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
        "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
        "\n",
        "    @staticmethod\n",
        "    def _cost_matrix(x, y, p=2):\n",
        "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
        "        x_col = x.unsqueeze(-2)\n",
        "        y_lin = y.unsqueeze(-3)\n",
        "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
        "        return C\n",
        "\n",
        "    @staticmethod\n",
        "    def ave(u, u1, tau):\n",
        "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
        "        return tau * u + (1 - tau) * u1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUaSGMMKCi8"
      },
      "source": [
        "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100, reduction=None).to(device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S4ipRioKCi8"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data.float()\n",
        "        \n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "           \n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGnghf6YKCi8"
      },
      "source": [
        "dataset = MyDataset(set_dist)\n",
        "loader = DataLoader(dataset, batch_size = 12, shuffle = True)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYh6UKUJKCi8",
        "outputId": "3ff169a2-1b99-4243-f731-662ed6697a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = DeepSet(2, 36).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# checkpoint = torch.load('normal_2D_2condition1.pt')\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "model.train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepSet(\n",
              "  (feature_extractor): Sequential(\n",
              "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
              "    (1): ELU(alpha=1.0, inplace=True)\n",
              "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
              "    (3): ELU(alpha=1.0, inplace=True)\n",
              "    (4): Linear(in_features=100, out_features=36, bias=True)\n",
              "  )\n",
              "  (regressor): Sequential(\n",
              "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
              "    (1): ELU(alpha=1.0, inplace=True)\n",
              "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
              "    (3): ELU(alpha=1.0, inplace=True)\n",
              "    (4): Linear(in_features=30, out_features=10, bias=True)\n",
              "    (5): ELU(alpha=1.0, inplace=True)\n",
              "    (6): Linear(in_features=10, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAwYo7w0KCi8"
      },
      "source": [
        "Wasserstein distance has the following properties: \n",
        "1) W(aX,aY) = |a|W(X,Y)\n",
        "2) W(X+x, Y+x) = W(X,Y)\n",
        "\n",
        "Only implement these properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ey28YjhKCi9",
        "outputId": "aacbde95-7efd-4b5c-9810-0b5840c892ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.random.seed(6345)\n",
        "torch.manual_seed(6345)\n",
        "num_epochs = 500\n",
        "running_loss = []\n",
        "\n",
        "for t in range(num_epochs):\n",
        "    for n_batch, batch in enumerate(loader):\n",
        "        n_data = Variable(batch.to(device), requires_grad=True)\n",
        "        a = torch.rand(1).to(device)\n",
        "        b = torch.rand(2).to(device)\n",
        "       \n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "        y = model(n_data)\n",
        "        y_a = model(a*n_data)\n",
        "        y_translate = model(n_data + b)\n",
        "        \n",
        "        loss = calculate_loss(batch, n_data, a, y, y_a, y_translate)\n",
        "        \n",
        "        loss = loss/(len(batch)*(len(batch)-1)/2)\n",
        "        \n",
        "       \n",
        "        loss.backward()\n",
        "    \n",
        "        optimizer.step()\n",
        "    \n",
        "        \n",
        "    running_loss.append(loss)\n",
        "    print(loss)\n",
        "   \n",
        "   "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nki79QYKCi-"
      },
      "source": [
        "# 196+41 epochs in\n",
        "torch.save({\n",
        "           \n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "            \n",
        "            }, 'normal_2D_2condition1.pt')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy5XFR2FKCi-",
        "outputId": "ca3cb14e-c8ae-4c9c-848a-579958f41a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(running_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii9aXsRxKCi-",
        "outputId": "51752b4f-8a23-4cce-d3fd-2edeceb730c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "running_loss"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.3933, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2933, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2532, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1736, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2241, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2035, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2803, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2478, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2558, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1811, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2434, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2752, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3033, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2778, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2985, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2279, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2387, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2958, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2537, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2086, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3365, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2000, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2118, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2860, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1930, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2476, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3150, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2728, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2125, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2755, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2269, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2131, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2517, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3464, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1795, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1604, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2409, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3628, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3006, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2742, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2122, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2166, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3200, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2317, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2938, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3609, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2654, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2290, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2239, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1282, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2830, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2129, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3923, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1868, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2202, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1983, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2452, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2533, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3460, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1566, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3248, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1862, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3087, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2376, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2467, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3534, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2502, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2812, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3416, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3929, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2630, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1580, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2370, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2506, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1601, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1809, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1874, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2145, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2215, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1801, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1998, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2673, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2745, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1518, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2160, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2200, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2159, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1899, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1621, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1988, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2008, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2657, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2650, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2146, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1770, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2015, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2365, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3050, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1493, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2210, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1898, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2667, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2207, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2323, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2836, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1957, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1912, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2451, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2358, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1563, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2173, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2491, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2060, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2643, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2528, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2935, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3760, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3945, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1452, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2647, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2590, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3337, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2518, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1995, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2635, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2002, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2346, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3253, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2390, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3068, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2172, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2155, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2802, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1937, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1598, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3218, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2175, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2932, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2503, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2936, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2099, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2494, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2242, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2709, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2185, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2243, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1949, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2049, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3158, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3054, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1782, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2162, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2182, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2486, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2171, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1996, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1892, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2825, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3896, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2887, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1981, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2920, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2422, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1840, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2316, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1496, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1250, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1944, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.4064, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3172, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3106, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2302, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2448, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3142, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2471, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2611, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1850, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1859, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1746, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3369, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2541, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2106, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3073, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2944, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2731, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2727, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3245, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2492, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2601, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2360, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2937, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1903, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3090, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2624, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2968, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2313, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3383, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3110, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1733, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2706, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2355, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2331, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2108, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2484, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2254, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2083, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2705, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2386, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2140, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2474, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2555, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2342, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1611, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3350, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2135, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2263, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2213, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1902, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2327, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2553, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1528, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2217, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2457, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1918, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1483, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2151, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2255, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3698, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2090, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2308, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2498, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2616, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3583, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2516, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2405, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2798, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2583, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2747, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3402, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2228, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2094, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2187, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2280, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1965, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2022, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3235, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.0731, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2058, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2549, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2081, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3549, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1534, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2441, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2485, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2621, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2232, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2564, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1616, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1936, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2027, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2791, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1717, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2973, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1677, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2098, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2032, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2774, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3368, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1731, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2025, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2756, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2787, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1349, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2359, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1323, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2400, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.3145, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1610, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2636, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2450, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2236, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2686, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2656, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2134, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2694, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2205, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2124, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2411, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2054, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2460, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1418, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2795, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2212, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1642, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2606, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2453, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2957, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1891, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2487, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2862, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2495, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2272, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2051, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2511, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2867, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2455, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2026, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1669, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2769, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.1484, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2271, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2772, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(0.2468, device='cuda:0', grad_fn=<DivBackward0>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74JMNyczKCi-"
      },
      "source": [
        "#Test ground truth\n",
        "#Cov mat_1 = ID, Cov mat_2 = [[1,.5], [.5,1]], m_1 = (0,0) , m_2 = (0,1)\n",
        "#Real Wass dist^2 = ||m_1 - m_2||^2 + (4-\\sqrt(2)-\\sqrt(6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xKJhltAKCi-"
      },
      "source": [
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSkv07j3KCi_"
      },
      "source": [
        "m1 = m.sample([250]).view(1,-1,2).to(device)\n",
        "m2 = m.sample([250]).view(1,-1,2).to(device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APXLAFi9KCi_"
      },
      "source": [
        " n = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0.0, 1.0]), torch.tensor([[1,.5],[.5,1]]))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlxLnvrmKCi_"
      },
      "source": [
        "n1 = n.sample([250]).view(1,-1,2).to(device)\n",
        "n2 = n.sample([250]).view(1,-1,2).to(device)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R95NNzXjKCi_",
        "outputId": "9864a78a-f3f1-4c4c-c666-f78fd6a2a2ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(m1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4903, -5.9006]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bEdxglGKCi_",
        "outputId": "09fa476b-4507-4fce-8951-785902364cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(m2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.2666, -6.0188]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGZSWxeyKCi_",
        "outputId": "bb7dd618-2658-4dc0-8821-a1675f030b8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(m1*.5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4615, -6.1914]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05donpeuKCi_",
        "outputId": "478e0299-9f8e-4b5f-e77b-cc8bb569eb5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(n1*.5)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.7539, -5.7813]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJdhm7jyKCjA",
        "outputId": "00887c33-cebd-4952-e1ad-1cae2fbd8260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(n1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0995, -5.1148]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUeASeAyKCjA"
      },
      "source": [
        "#calculated distance = 1.336, scaling by .5 get distance to be .7 and moving them around got 1.323"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myQJPkjxKCjA",
        "outputId": "8f75f497-cb1f-4be0-f972-5db291adc20a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(m1+.8)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9079, -4.2803]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ltU0Kp7AKCjA",
        "outputId": "5d514b86-3eb7-4f0d-8275-3003e319dfd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(n1+.8)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5489, -3.4706]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hazlLYA3KCjC",
        "outputId": "2d7f33a6-27d2-4703-9782-42b5487bb457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sinkhorn(m1+.5, n1+.5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.4789], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK5NB9WCKCjD",
        "outputId": "b18b77a5-c634-4631-b4cc-15a4e04e25bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sinkhorn(m1,n1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.4789], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWX50ezuKCjD",
        "outputId": "5f559f95-4510-4cca-bfef-d24470ab486b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sinkhorn(m1*.5, n1*.5)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4361], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWNIW9JjKCjD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}